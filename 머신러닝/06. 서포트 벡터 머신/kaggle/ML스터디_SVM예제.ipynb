{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Support Vector Machine (SVM)\n   \n   \n### 본 캐글 코드는 아래와 같은 순서로 작성됨.  \n   \n   \n1. 데이터 전처리\n2. default hyperparameter를 사용한 SVM 모델     \n   2.1. default linear kernel   \n   2.2. default RBF kernel   \n   2.3. default polynomial kernel\n3. 각 SVM 모델 별 parameter 최적화   \n   3.1. linear kernel : C\n   3.2. RBF kernel : C, gamma   \n   3.3. polynomial kernel : C, gamma, degree   \n   \n________ \n\n* 위 파트 중, 3파트의 경우 sklearn.cross_validation, sklearn.grid_search를 load 해야 함.   \n* 본 코드는 캐글 사이트에서 작성되었으나, 위의 두 모듈이 load 되지 않음.   \n* 제대로 load 되었을 시 작성해야 하는 코드는 작성해 두었으니, 개인 python 환경에서 문제 없이 load 되면 실행해 보시면 좋을 것 같습니다!"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":2,"outputs":[{"output_type":"stream","text":"/kaggle/input/voicegender/voice.csv\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## 1. 데이터 전처리"},{"metadata":{"trusted":true},"cell_type":"code","source":"# load library\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data load\ndf = pd.read_csv(\"/kaggle/input/voicegender/voice.csv\")\ndf.head()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n\n          kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n0   274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n1   634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n2  1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n3     4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n4     4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n\n     maxfun   meandom    mindom    maxdom   dfrange   modindx  label  \n0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000   male  \n1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632   male  \n2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512   male  \n3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119   male  \n4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274   male  \n\n[5 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>meanfreq</th>\n      <th>sd</th>\n      <th>median</th>\n      <th>Q25</th>\n      <th>Q75</th>\n      <th>IQR</th>\n      <th>skew</th>\n      <th>kurt</th>\n      <th>sp.ent</th>\n      <th>sfm</th>\n      <th>...</th>\n      <th>centroid</th>\n      <th>meanfun</th>\n      <th>minfun</th>\n      <th>maxfun</th>\n      <th>meandom</th>\n      <th>mindom</th>\n      <th>maxdom</th>\n      <th>dfrange</th>\n      <th>modindx</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.059781</td>\n      <td>0.064241</td>\n      <td>0.032027</td>\n      <td>0.015071</td>\n      <td>0.090193</td>\n      <td>0.075122</td>\n      <td>12.863462</td>\n      <td>274.402906</td>\n      <td>0.893369</td>\n      <td>0.491918</td>\n      <td>...</td>\n      <td>0.059781</td>\n      <td>0.084279</td>\n      <td>0.015702</td>\n      <td>0.275862</td>\n      <td>0.007812</td>\n      <td>0.007812</td>\n      <td>0.007812</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.066009</td>\n      <td>0.067310</td>\n      <td>0.040229</td>\n      <td>0.019414</td>\n      <td>0.092666</td>\n      <td>0.073252</td>\n      <td>22.423285</td>\n      <td>634.613855</td>\n      <td>0.892193</td>\n      <td>0.513724</td>\n      <td>...</td>\n      <td>0.066009</td>\n      <td>0.107937</td>\n      <td>0.015826</td>\n      <td>0.250000</td>\n      <td>0.009014</td>\n      <td>0.007812</td>\n      <td>0.054688</td>\n      <td>0.046875</td>\n      <td>0.052632</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.077316</td>\n      <td>0.083829</td>\n      <td>0.036718</td>\n      <td>0.008701</td>\n      <td>0.131908</td>\n      <td>0.123207</td>\n      <td>30.757155</td>\n      <td>1024.927705</td>\n      <td>0.846389</td>\n      <td>0.478905</td>\n      <td>...</td>\n      <td>0.077316</td>\n      <td>0.098706</td>\n      <td>0.015656</td>\n      <td>0.271186</td>\n      <td>0.007990</td>\n      <td>0.007812</td>\n      <td>0.015625</td>\n      <td>0.007812</td>\n      <td>0.046512</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.151228</td>\n      <td>0.072111</td>\n      <td>0.158011</td>\n      <td>0.096582</td>\n      <td>0.207955</td>\n      <td>0.111374</td>\n      <td>1.232831</td>\n      <td>4.177296</td>\n      <td>0.963322</td>\n      <td>0.727232</td>\n      <td>...</td>\n      <td>0.151228</td>\n      <td>0.088965</td>\n      <td>0.017798</td>\n      <td>0.250000</td>\n      <td>0.201497</td>\n      <td>0.007812</td>\n      <td>0.562500</td>\n      <td>0.554688</td>\n      <td>0.247119</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.135120</td>\n      <td>0.079146</td>\n      <td>0.124656</td>\n      <td>0.078720</td>\n      <td>0.206045</td>\n      <td>0.127325</td>\n      <td>1.101174</td>\n      <td>4.333713</td>\n      <td>0.971955</td>\n      <td>0.783568</td>\n      <td>...</td>\n      <td>0.135120</td>\n      <td>0.106398</td>\n      <td>0.016931</td>\n      <td>0.266667</td>\n      <td>0.712812</td>\n      <td>0.007812</td>\n      <td>5.484375</td>\n      <td>5.476562</td>\n      <td>0.208274</td>\n      <td>male</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 각 feature 간의 correlation 확인\ndf.corr()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"          meanfreq        sd    median       Q25       Q75       IQR  \\\nmeanfreq  1.000000 -0.739039  0.925445  0.911416  0.740997 -0.627605   \nsd       -0.739039  1.000000 -0.562603 -0.846931 -0.161076  0.874660   \nmedian    0.925445 -0.562603  1.000000  0.774922  0.731849 -0.477352   \nQ25       0.911416 -0.846931  0.774922  1.000000  0.477140 -0.874189   \nQ75       0.740997 -0.161076  0.731849  0.477140  1.000000  0.009636   \nIQR      -0.627605  0.874660 -0.477352 -0.874189  0.009636  1.000000   \nskew     -0.322327  0.314597 -0.257407 -0.319475 -0.206339  0.249497   \nkurt     -0.316036  0.346241 -0.243382 -0.350182 -0.148881  0.316185   \nsp.ent   -0.601203  0.716620 -0.502005 -0.648126 -0.174905  0.640813   \nsfm      -0.784332  0.838086 -0.661690 -0.766875 -0.378198  0.663601   \nmode      0.687715 -0.529150  0.677433  0.591277  0.486857 -0.403764   \ncentroid  1.000000 -0.739039  0.925445  0.911416  0.740997 -0.627605   \nmeanfun   0.460844 -0.466281  0.414909  0.545035  0.155091 -0.534462   \nminfun    0.383937 -0.345609  0.337602  0.320994  0.258002 -0.222680   \nmaxfun    0.274004 -0.129662  0.251328  0.199841  0.285584 -0.069588   \nmeandom   0.536666 -0.482726  0.455943  0.467403  0.359181 -0.333362   \nmindom    0.229261 -0.357667  0.191169  0.302255 -0.023750 -0.357037   \nmaxdom    0.519528 -0.482278  0.438919  0.459683  0.335114 -0.337877   \ndfrange   0.515570 -0.475999  0.435621  0.454394  0.335648 -0.331563   \nmodindx  -0.216979  0.122660 -0.213298 -0.141377 -0.216475  0.041252   \n\n              skew      kurt    sp.ent       sfm      mode  centroid  \\\nmeanfreq -0.322327 -0.316036 -0.601203 -0.784332  0.687715  1.000000   \nsd        0.314597  0.346241  0.716620  0.838086 -0.529150 -0.739039   \nmedian   -0.257407 -0.243382 -0.502005 -0.661690  0.677433  0.925445   \nQ25      -0.319475 -0.350182 -0.648126 -0.766875  0.591277  0.911416   \nQ75      -0.206339 -0.148881 -0.174905 -0.378198  0.486857  0.740997   \nIQR       0.249497  0.316185  0.640813  0.663601 -0.403764 -0.627605   \nskew      1.000000  0.977020 -0.195459  0.079694 -0.434859 -0.322327   \nkurt      0.977020  1.000000 -0.127644  0.109884 -0.406722 -0.316036   \nsp.ent   -0.195459 -0.127644  1.000000  0.866411 -0.325298 -0.601203   \nsfm       0.079694  0.109884  0.866411  1.000000 -0.485913 -0.784332   \nmode     -0.434859 -0.406722 -0.325298 -0.485913  1.000000  0.687715   \ncentroid -0.322327 -0.316036 -0.601203 -0.784332  0.687715  1.000000   \nmeanfun  -0.167668 -0.194560 -0.513194 -0.421066  0.324771  0.460844   \nminfun   -0.216954 -0.203201 -0.305826 -0.362100  0.385467  0.383937   \nmaxfun   -0.080861 -0.045667 -0.120738 -0.192369  0.172329  0.274004   \nmeandom  -0.336848 -0.303234 -0.293562 -0.428442  0.491479  0.536666   \nmindom   -0.061608 -0.103313 -0.294869 -0.289593  0.198150  0.229261   \nmaxdom   -0.305651 -0.274500 -0.324253 -0.436649  0.477187  0.519528   \ndfrange  -0.304640 -0.272729 -0.319054 -0.431580  0.473775  0.515570   \nmodindx  -0.169325 -0.205539  0.198074  0.211477 -0.182344 -0.216979   \n\n           meanfun    minfun    maxfun   meandom    mindom    maxdom  \\\nmeanfreq  0.460844  0.383937  0.274004  0.536666  0.229261  0.519528   \nsd       -0.466281 -0.345609 -0.129662 -0.482726 -0.357667 -0.482278   \nmedian    0.414909  0.337602  0.251328  0.455943  0.191169  0.438919   \nQ25       0.545035  0.320994  0.199841  0.467403  0.302255  0.459683   \nQ75       0.155091  0.258002  0.285584  0.359181 -0.023750  0.335114   \nIQR      -0.534462 -0.222680 -0.069588 -0.333362 -0.357037 -0.337877   \nskew     -0.167668 -0.216954 -0.080861 -0.336848 -0.061608 -0.305651   \nkurt     -0.194560 -0.203201 -0.045667 -0.303234 -0.103313 -0.274500   \nsp.ent   -0.513194 -0.305826 -0.120738 -0.293562 -0.294869 -0.324253   \nsfm      -0.421066 -0.362100 -0.192369 -0.428442 -0.289593 -0.436649   \nmode      0.324771  0.385467  0.172329  0.491479  0.198150  0.477187   \ncentroid  0.460844  0.383937  0.274004  0.536666  0.229261  0.519528   \nmeanfun   1.000000  0.339387  0.311950  0.270840  0.162163  0.277982   \nminfun    0.339387  1.000000  0.213987  0.375979  0.082015  0.317860   \nmaxfun    0.311950  0.213987  1.000000  0.337553 -0.243426  0.355390   \nmeandom   0.270840  0.375979  0.337553  1.000000  0.099656  0.812838   \nmindom    0.162163  0.082015 -0.243426  0.099656  1.000000  0.026640   \nmaxdom    0.277982  0.317860  0.355390  0.812838  0.026640  1.000000   \ndfrange   0.275154  0.316486  0.359880  0.811304  0.008666  0.999838   \nmodindx  -0.054858  0.002042 -0.363029 -0.180954  0.200212 -0.425531   \n\n           dfrange   modindx  \nmeanfreq  0.515570 -0.216979  \nsd       -0.475999  0.122660  \nmedian    0.435621 -0.213298  \nQ25       0.454394 -0.141377  \nQ75       0.335648 -0.216475  \nIQR      -0.331563  0.041252  \nskew     -0.304640 -0.169325  \nkurt     -0.272729 -0.205539  \nsp.ent   -0.319054  0.198074  \nsfm      -0.431580  0.211477  \nmode      0.473775 -0.182344  \ncentroid  0.515570 -0.216979  \nmeanfun   0.275154 -0.054858  \nminfun    0.316486  0.002042  \nmaxfun    0.359880 -0.363029  \nmeandom   0.811304 -0.180954  \nmindom    0.008666  0.200212  \nmaxdom    0.999838 -0.425531  \ndfrange   1.000000 -0.429266  \nmodindx  -0.429266  1.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>meanfreq</th>\n      <th>sd</th>\n      <th>median</th>\n      <th>Q25</th>\n      <th>Q75</th>\n      <th>IQR</th>\n      <th>skew</th>\n      <th>kurt</th>\n      <th>sp.ent</th>\n      <th>sfm</th>\n      <th>mode</th>\n      <th>centroid</th>\n      <th>meanfun</th>\n      <th>minfun</th>\n      <th>maxfun</th>\n      <th>meandom</th>\n      <th>mindom</th>\n      <th>maxdom</th>\n      <th>dfrange</th>\n      <th>modindx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>meanfreq</th>\n      <td>1.000000</td>\n      <td>-0.739039</td>\n      <td>0.925445</td>\n      <td>0.911416</td>\n      <td>0.740997</td>\n      <td>-0.627605</td>\n      <td>-0.322327</td>\n      <td>-0.316036</td>\n      <td>-0.601203</td>\n      <td>-0.784332</td>\n      <td>0.687715</td>\n      <td>1.000000</td>\n      <td>0.460844</td>\n      <td>0.383937</td>\n      <td>0.274004</td>\n      <td>0.536666</td>\n      <td>0.229261</td>\n      <td>0.519528</td>\n      <td>0.515570</td>\n      <td>-0.216979</td>\n    </tr>\n    <tr>\n      <th>sd</th>\n      <td>-0.739039</td>\n      <td>1.000000</td>\n      <td>-0.562603</td>\n      <td>-0.846931</td>\n      <td>-0.161076</td>\n      <td>0.874660</td>\n      <td>0.314597</td>\n      <td>0.346241</td>\n      <td>0.716620</td>\n      <td>0.838086</td>\n      <td>-0.529150</td>\n      <td>-0.739039</td>\n      <td>-0.466281</td>\n      <td>-0.345609</td>\n      <td>-0.129662</td>\n      <td>-0.482726</td>\n      <td>-0.357667</td>\n      <td>-0.482278</td>\n      <td>-0.475999</td>\n      <td>0.122660</td>\n    </tr>\n    <tr>\n      <th>median</th>\n      <td>0.925445</td>\n      <td>-0.562603</td>\n      <td>1.000000</td>\n      <td>0.774922</td>\n      <td>0.731849</td>\n      <td>-0.477352</td>\n      <td>-0.257407</td>\n      <td>-0.243382</td>\n      <td>-0.502005</td>\n      <td>-0.661690</td>\n      <td>0.677433</td>\n      <td>0.925445</td>\n      <td>0.414909</td>\n      <td>0.337602</td>\n      <td>0.251328</td>\n      <td>0.455943</td>\n      <td>0.191169</td>\n      <td>0.438919</td>\n      <td>0.435621</td>\n      <td>-0.213298</td>\n    </tr>\n    <tr>\n      <th>Q25</th>\n      <td>0.911416</td>\n      <td>-0.846931</td>\n      <td>0.774922</td>\n      <td>1.000000</td>\n      <td>0.477140</td>\n      <td>-0.874189</td>\n      <td>-0.319475</td>\n      <td>-0.350182</td>\n      <td>-0.648126</td>\n      <td>-0.766875</td>\n      <td>0.591277</td>\n      <td>0.911416</td>\n      <td>0.545035</td>\n      <td>0.320994</td>\n      <td>0.199841</td>\n      <td>0.467403</td>\n      <td>0.302255</td>\n      <td>0.459683</td>\n      <td>0.454394</td>\n      <td>-0.141377</td>\n    </tr>\n    <tr>\n      <th>Q75</th>\n      <td>0.740997</td>\n      <td>-0.161076</td>\n      <td>0.731849</td>\n      <td>0.477140</td>\n      <td>1.000000</td>\n      <td>0.009636</td>\n      <td>-0.206339</td>\n      <td>-0.148881</td>\n      <td>-0.174905</td>\n      <td>-0.378198</td>\n      <td>0.486857</td>\n      <td>0.740997</td>\n      <td>0.155091</td>\n      <td>0.258002</td>\n      <td>0.285584</td>\n      <td>0.359181</td>\n      <td>-0.023750</td>\n      <td>0.335114</td>\n      <td>0.335648</td>\n      <td>-0.216475</td>\n    </tr>\n    <tr>\n      <th>IQR</th>\n      <td>-0.627605</td>\n      <td>0.874660</td>\n      <td>-0.477352</td>\n      <td>-0.874189</td>\n      <td>0.009636</td>\n      <td>1.000000</td>\n      <td>0.249497</td>\n      <td>0.316185</td>\n      <td>0.640813</td>\n      <td>0.663601</td>\n      <td>-0.403764</td>\n      <td>-0.627605</td>\n      <td>-0.534462</td>\n      <td>-0.222680</td>\n      <td>-0.069588</td>\n      <td>-0.333362</td>\n      <td>-0.357037</td>\n      <td>-0.337877</td>\n      <td>-0.331563</td>\n      <td>0.041252</td>\n    </tr>\n    <tr>\n      <th>skew</th>\n      <td>-0.322327</td>\n      <td>0.314597</td>\n      <td>-0.257407</td>\n      <td>-0.319475</td>\n      <td>-0.206339</td>\n      <td>0.249497</td>\n      <td>1.000000</td>\n      <td>0.977020</td>\n      <td>-0.195459</td>\n      <td>0.079694</td>\n      <td>-0.434859</td>\n      <td>-0.322327</td>\n      <td>-0.167668</td>\n      <td>-0.216954</td>\n      <td>-0.080861</td>\n      <td>-0.336848</td>\n      <td>-0.061608</td>\n      <td>-0.305651</td>\n      <td>-0.304640</td>\n      <td>-0.169325</td>\n    </tr>\n    <tr>\n      <th>kurt</th>\n      <td>-0.316036</td>\n      <td>0.346241</td>\n      <td>-0.243382</td>\n      <td>-0.350182</td>\n      <td>-0.148881</td>\n      <td>0.316185</td>\n      <td>0.977020</td>\n      <td>1.000000</td>\n      <td>-0.127644</td>\n      <td>0.109884</td>\n      <td>-0.406722</td>\n      <td>-0.316036</td>\n      <td>-0.194560</td>\n      <td>-0.203201</td>\n      <td>-0.045667</td>\n      <td>-0.303234</td>\n      <td>-0.103313</td>\n      <td>-0.274500</td>\n      <td>-0.272729</td>\n      <td>-0.205539</td>\n    </tr>\n    <tr>\n      <th>sp.ent</th>\n      <td>-0.601203</td>\n      <td>0.716620</td>\n      <td>-0.502005</td>\n      <td>-0.648126</td>\n      <td>-0.174905</td>\n      <td>0.640813</td>\n      <td>-0.195459</td>\n      <td>-0.127644</td>\n      <td>1.000000</td>\n      <td>0.866411</td>\n      <td>-0.325298</td>\n      <td>-0.601203</td>\n      <td>-0.513194</td>\n      <td>-0.305826</td>\n      <td>-0.120738</td>\n      <td>-0.293562</td>\n      <td>-0.294869</td>\n      <td>-0.324253</td>\n      <td>-0.319054</td>\n      <td>0.198074</td>\n    </tr>\n    <tr>\n      <th>sfm</th>\n      <td>-0.784332</td>\n      <td>0.838086</td>\n      <td>-0.661690</td>\n      <td>-0.766875</td>\n      <td>-0.378198</td>\n      <td>0.663601</td>\n      <td>0.079694</td>\n      <td>0.109884</td>\n      <td>0.866411</td>\n      <td>1.000000</td>\n      <td>-0.485913</td>\n      <td>-0.784332</td>\n      <td>-0.421066</td>\n      <td>-0.362100</td>\n      <td>-0.192369</td>\n      <td>-0.428442</td>\n      <td>-0.289593</td>\n      <td>-0.436649</td>\n      <td>-0.431580</td>\n      <td>0.211477</td>\n    </tr>\n    <tr>\n      <th>mode</th>\n      <td>0.687715</td>\n      <td>-0.529150</td>\n      <td>0.677433</td>\n      <td>0.591277</td>\n      <td>0.486857</td>\n      <td>-0.403764</td>\n      <td>-0.434859</td>\n      <td>-0.406722</td>\n      <td>-0.325298</td>\n      <td>-0.485913</td>\n      <td>1.000000</td>\n      <td>0.687715</td>\n      <td>0.324771</td>\n      <td>0.385467</td>\n      <td>0.172329</td>\n      <td>0.491479</td>\n      <td>0.198150</td>\n      <td>0.477187</td>\n      <td>0.473775</td>\n      <td>-0.182344</td>\n    </tr>\n    <tr>\n      <th>centroid</th>\n      <td>1.000000</td>\n      <td>-0.739039</td>\n      <td>0.925445</td>\n      <td>0.911416</td>\n      <td>0.740997</td>\n      <td>-0.627605</td>\n      <td>-0.322327</td>\n      <td>-0.316036</td>\n      <td>-0.601203</td>\n      <td>-0.784332</td>\n      <td>0.687715</td>\n      <td>1.000000</td>\n      <td>0.460844</td>\n      <td>0.383937</td>\n      <td>0.274004</td>\n      <td>0.536666</td>\n      <td>0.229261</td>\n      <td>0.519528</td>\n      <td>0.515570</td>\n      <td>-0.216979</td>\n    </tr>\n    <tr>\n      <th>meanfun</th>\n      <td>0.460844</td>\n      <td>-0.466281</td>\n      <td>0.414909</td>\n      <td>0.545035</td>\n      <td>0.155091</td>\n      <td>-0.534462</td>\n      <td>-0.167668</td>\n      <td>-0.194560</td>\n      <td>-0.513194</td>\n      <td>-0.421066</td>\n      <td>0.324771</td>\n      <td>0.460844</td>\n      <td>1.000000</td>\n      <td>0.339387</td>\n      <td>0.311950</td>\n      <td>0.270840</td>\n      <td>0.162163</td>\n      <td>0.277982</td>\n      <td>0.275154</td>\n      <td>-0.054858</td>\n    </tr>\n    <tr>\n      <th>minfun</th>\n      <td>0.383937</td>\n      <td>-0.345609</td>\n      <td>0.337602</td>\n      <td>0.320994</td>\n      <td>0.258002</td>\n      <td>-0.222680</td>\n      <td>-0.216954</td>\n      <td>-0.203201</td>\n      <td>-0.305826</td>\n      <td>-0.362100</td>\n      <td>0.385467</td>\n      <td>0.383937</td>\n      <td>0.339387</td>\n      <td>1.000000</td>\n      <td>0.213987</td>\n      <td>0.375979</td>\n      <td>0.082015</td>\n      <td>0.317860</td>\n      <td>0.316486</td>\n      <td>0.002042</td>\n    </tr>\n    <tr>\n      <th>maxfun</th>\n      <td>0.274004</td>\n      <td>-0.129662</td>\n      <td>0.251328</td>\n      <td>0.199841</td>\n      <td>0.285584</td>\n      <td>-0.069588</td>\n      <td>-0.080861</td>\n      <td>-0.045667</td>\n      <td>-0.120738</td>\n      <td>-0.192369</td>\n      <td>0.172329</td>\n      <td>0.274004</td>\n      <td>0.311950</td>\n      <td>0.213987</td>\n      <td>1.000000</td>\n      <td>0.337553</td>\n      <td>-0.243426</td>\n      <td>0.355390</td>\n      <td>0.359880</td>\n      <td>-0.363029</td>\n    </tr>\n    <tr>\n      <th>meandom</th>\n      <td>0.536666</td>\n      <td>-0.482726</td>\n      <td>0.455943</td>\n      <td>0.467403</td>\n      <td>0.359181</td>\n      <td>-0.333362</td>\n      <td>-0.336848</td>\n      <td>-0.303234</td>\n      <td>-0.293562</td>\n      <td>-0.428442</td>\n      <td>0.491479</td>\n      <td>0.536666</td>\n      <td>0.270840</td>\n      <td>0.375979</td>\n      <td>0.337553</td>\n      <td>1.000000</td>\n      <td>0.099656</td>\n      <td>0.812838</td>\n      <td>0.811304</td>\n      <td>-0.180954</td>\n    </tr>\n    <tr>\n      <th>mindom</th>\n      <td>0.229261</td>\n      <td>-0.357667</td>\n      <td>0.191169</td>\n      <td>0.302255</td>\n      <td>-0.023750</td>\n      <td>-0.357037</td>\n      <td>-0.061608</td>\n      <td>-0.103313</td>\n      <td>-0.294869</td>\n      <td>-0.289593</td>\n      <td>0.198150</td>\n      <td>0.229261</td>\n      <td>0.162163</td>\n      <td>0.082015</td>\n      <td>-0.243426</td>\n      <td>0.099656</td>\n      <td>1.000000</td>\n      <td>0.026640</td>\n      <td>0.008666</td>\n      <td>0.200212</td>\n    </tr>\n    <tr>\n      <th>maxdom</th>\n      <td>0.519528</td>\n      <td>-0.482278</td>\n      <td>0.438919</td>\n      <td>0.459683</td>\n      <td>0.335114</td>\n      <td>-0.337877</td>\n      <td>-0.305651</td>\n      <td>-0.274500</td>\n      <td>-0.324253</td>\n      <td>-0.436649</td>\n      <td>0.477187</td>\n      <td>0.519528</td>\n      <td>0.277982</td>\n      <td>0.317860</td>\n      <td>0.355390</td>\n      <td>0.812838</td>\n      <td>0.026640</td>\n      <td>1.000000</td>\n      <td>0.999838</td>\n      <td>-0.425531</td>\n    </tr>\n    <tr>\n      <th>dfrange</th>\n      <td>0.515570</td>\n      <td>-0.475999</td>\n      <td>0.435621</td>\n      <td>0.454394</td>\n      <td>0.335648</td>\n      <td>-0.331563</td>\n      <td>-0.304640</td>\n      <td>-0.272729</td>\n      <td>-0.319054</td>\n      <td>-0.431580</td>\n      <td>0.473775</td>\n      <td>0.515570</td>\n      <td>0.275154</td>\n      <td>0.316486</td>\n      <td>0.359880</td>\n      <td>0.811304</td>\n      <td>0.008666</td>\n      <td>0.999838</td>\n      <td>1.000000</td>\n      <td>-0.429266</td>\n    </tr>\n    <tr>\n      <th>modindx</th>\n      <td>-0.216979</td>\n      <td>0.122660</td>\n      <td>-0.213298</td>\n      <td>-0.141377</td>\n      <td>-0.216475</td>\n      <td>0.041252</td>\n      <td>-0.169325</td>\n      <td>-0.205539</td>\n      <td>0.198074</td>\n      <td>0.211477</td>\n      <td>-0.182344</td>\n      <td>-0.216979</td>\n      <td>-0.054858</td>\n      <td>0.002042</td>\n      <td>-0.363029</td>\n      <td>-0.180954</td>\n      <td>0.200212</td>\n      <td>-0.425531</td>\n      <td>-0.429266</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# null값 여부 확인\ndf.isnull().sum()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"meanfreq    0\nsd          0\nmedian      0\nQ25         0\nQ75         0\nIQR         0\nskew        0\nkurt        0\nsp.ent      0\nsfm         0\nmode        0\ncentroid    0\nmeanfun     0\nminfun      0\nmaxfun      0\nmeandom     0\nmindom      0\nmaxdom      0\ndfrange     0\nmodindx     0\nlabel       0\ndtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# separating features and labels\nX = df.iloc[:,:-1]\nX.head()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n\n          kurt    sp.ent       sfm      mode  centroid   meanfun    minfun  \\\n0   274.402906  0.893369  0.491918  0.000000  0.059781  0.084279  0.015702   \n1   634.613855  0.892193  0.513724  0.000000  0.066009  0.107937  0.015826   \n2  1024.927705  0.846389  0.478905  0.000000  0.077316  0.098706  0.015656   \n3     4.177296  0.963322  0.727232  0.083878  0.151228  0.088965  0.017798   \n4     4.333713  0.971955  0.783568  0.104261  0.135120  0.106398  0.016931   \n\n     maxfun   meandom    mindom    maxdom   dfrange   modindx  \n0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000  \n1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632  \n2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512  \n3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119  \n4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>meanfreq</th>\n      <th>sd</th>\n      <th>median</th>\n      <th>Q25</th>\n      <th>Q75</th>\n      <th>IQR</th>\n      <th>skew</th>\n      <th>kurt</th>\n      <th>sp.ent</th>\n      <th>sfm</th>\n      <th>mode</th>\n      <th>centroid</th>\n      <th>meanfun</th>\n      <th>minfun</th>\n      <th>maxfun</th>\n      <th>meandom</th>\n      <th>mindom</th>\n      <th>maxdom</th>\n      <th>dfrange</th>\n      <th>modindx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.059781</td>\n      <td>0.064241</td>\n      <td>0.032027</td>\n      <td>0.015071</td>\n      <td>0.090193</td>\n      <td>0.075122</td>\n      <td>12.863462</td>\n      <td>274.402906</td>\n      <td>0.893369</td>\n      <td>0.491918</td>\n      <td>0.000000</td>\n      <td>0.059781</td>\n      <td>0.084279</td>\n      <td>0.015702</td>\n      <td>0.275862</td>\n      <td>0.007812</td>\n      <td>0.007812</td>\n      <td>0.007812</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.066009</td>\n      <td>0.067310</td>\n      <td>0.040229</td>\n      <td>0.019414</td>\n      <td>0.092666</td>\n      <td>0.073252</td>\n      <td>22.423285</td>\n      <td>634.613855</td>\n      <td>0.892193</td>\n      <td>0.513724</td>\n      <td>0.000000</td>\n      <td>0.066009</td>\n      <td>0.107937</td>\n      <td>0.015826</td>\n      <td>0.250000</td>\n      <td>0.009014</td>\n      <td>0.007812</td>\n      <td>0.054688</td>\n      <td>0.046875</td>\n      <td>0.052632</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.077316</td>\n      <td>0.083829</td>\n      <td>0.036718</td>\n      <td>0.008701</td>\n      <td>0.131908</td>\n      <td>0.123207</td>\n      <td>30.757155</td>\n      <td>1024.927705</td>\n      <td>0.846389</td>\n      <td>0.478905</td>\n      <td>0.000000</td>\n      <td>0.077316</td>\n      <td>0.098706</td>\n      <td>0.015656</td>\n      <td>0.271186</td>\n      <td>0.007990</td>\n      <td>0.007812</td>\n      <td>0.015625</td>\n      <td>0.007812</td>\n      <td>0.046512</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.151228</td>\n      <td>0.072111</td>\n      <td>0.158011</td>\n      <td>0.096582</td>\n      <td>0.207955</td>\n      <td>0.111374</td>\n      <td>1.232831</td>\n      <td>4.177296</td>\n      <td>0.963322</td>\n      <td>0.727232</td>\n      <td>0.083878</td>\n      <td>0.151228</td>\n      <td>0.088965</td>\n      <td>0.017798</td>\n      <td>0.250000</td>\n      <td>0.201497</td>\n      <td>0.007812</td>\n      <td>0.562500</td>\n      <td>0.554688</td>\n      <td>0.247119</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.135120</td>\n      <td>0.079146</td>\n      <td>0.124656</td>\n      <td>0.078720</td>\n      <td>0.206045</td>\n      <td>0.127325</td>\n      <td>1.101174</td>\n      <td>4.333713</td>\n      <td>0.971955</td>\n      <td>0.783568</td>\n      <td>0.104261</td>\n      <td>0.135120</td>\n      <td>0.106398</td>\n      <td>0.016931</td>\n      <td>0.266667</td>\n      <td>0.712812</td>\n      <td>0.007812</td>\n      <td>5.484375</td>\n      <td>5.476562</td>\n      <td>0.208274</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# label 컬럼의 성별(문자형 컬럼)을 숫자형으로 변경\nfrom sklearn.preprocessing import LabelEncoder\ny = df.iloc[:,-1]\n\n# male -> 1, female -> 0으로 변경\n\ngender_encoder = LabelEncoder()\ny = gender_encoder.fit_transform(y)\ny","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"array([1, 1, 1, ..., 0, 0, 0])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"* 데이터 표준화 (Data Standardisation)\n  \n데이터 표준화는 각 feature의 분포를 평균=0, 표준편차=1인 분포가 되도록 이동하는 것.    \n만약 각 feature이 표준 정규 분포 형태를 이루지 않는다면, 적용 시 조심해야 함."},{"metadata":{"trusted":true},"cell_type":"code","source":"# 각 데이터 값을 -1과 1 사이로 변경\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X)\nX = scaler.transform(X)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train set과 test set으로 변경\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n#test set은 전체 데이터의 20%만 선택","execution_count":10,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. default hyperparameter를 사용한 SVM 모델"},{"metadata":{},"cell_type":"markdown","source":"* SVM (using default hyperparameter)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn import metrics\nsvc = SVC()\nsvc.fit(X_train, y_train)\ny_pred = svc.predict(X_test)\nprint('Accuracy Score :')\nprint(metrics.accuracy_score(y_test,y_pred))","execution_count":11,"outputs":[{"output_type":"stream","text":"Accuracy Score :\n0.9763406940063092\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"* SVM (using default linear kernel)"},{"metadata":{"trusted":true},"cell_type":"code","source":"svc = SVC(kernel='linear')\nsvc.fit(X_train, y_train)\ny_pred = svc.predict(X_test)\nprint('Accuracy Score :')\nprint(metrics.accuracy_score(y_test,y_pred))","execution_count":12,"outputs":[{"output_type":"stream","text":"Accuracy Score :\n0.9779179810725552\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"* SVM (using default RBF kernel)"},{"metadata":{"trusted":true},"cell_type":"code","source":"svc = SVC(kernel='rbf')\nsvc.fit(X_train, y_train)\ny_pred = svc.predict(X_test)\nprint('Accuracy Score :')\nprint(metrics.accuracy_score(y_test,y_pred))","execution_count":13,"outputs":[{"output_type":"stream","text":"Accuracy Score :\n0.9763406940063092\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"* SVM (using default polynomial kernel)"},{"metadata":{"trusted":true},"cell_type":"code","source":"svc = SVC(kernel='poly')\nsvc.fit(X_train, y_train)\ny_pred = svc.predict(X_test)\nprint('Accuracy Score :')\nprint(metrics.accuracy_score(y_test,y_pred))\n# 정확도 하락 (polynomial kernel은 training dataset을 overfitting해서 일 가능성 존재)","execution_count":14,"outputs":[{"output_type":"stream","text":"Accuracy Score :\n0.9589905362776026\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"default kernel을 사용한 세 경우의 정확도는 다음과 같음.\n* default linear kernel : 0.9779179810725552\n* default RBF kernel : 0.9763406940063092\n* default polynomial kernel : 0.9589905362776026\n    \n위의 세 경우의 정확도가 다르게 나온 이유는 전체 data set을 train / test set으로 나누는 방법 때문   \n본 코드에서는 train / test set을 랜덤하게 나눔.   \n따라서, 어떤 데이터들이 train set으로 들어가고, test set이 어떻게 분포되어있는가에 따라 정확도가 달라질 수 있음."},{"metadata":{},"cell_type":"markdown","source":"## 3. 각 SVM 모델 별 parameter 최적화"},{"metadata":{},"cell_type":"markdown","source":"SVM에서 C 파라미터란, 얼마나 각 training 예제를 misclassifying 하지 않을 것인지 결정하는 SVM 파라미터를 의미함.   \nC를 크게 설정하면, hyperplane이 모든 training point를 가장 잘 분류할 수 있는, smaller-margin을 선택하게 됨.   \nC를 작게 설정하면, larger-margin이 선택되며, 이 경우에는 hyperplane이 point 중 여러 개를 잘못 분류하게 될 수 있음.   \n   \n따라서, C를 매우 크게 설정하면 모델의 과적합을 유발할 수 있으며, C를 매우 작게 설정하면 과소 적합을 유발할 수 있음.  \n따라서, C 값은 주어진 데이터들을 일반화할 수 있는 값으로 설정되어야 함.  \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cross_validation import cross_val_score\n# 본 노트북은 캐글 사이트에서 작성되었음.\n# 캐글에서 sklearn.cross_validation을 load하는데 문제가 생김.\n# 개인의 python 설정 상에서 sklearn.cross_validation을 load할 수 있으면, 아래 코드를 통해 C 값에 따른 정확도를 확인할 수 있을 것임.","execution_count":16,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'sklearn.cross_validation'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-752bb1bee8c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.cross_validation'"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# C 값의 범의를 1부터 26으로 변화를 주며, 정확도 확인\nC_range=list(range(1,26))\nacc_score=[]\nfor c in C_range:\n    svc = SVC(kernel='linear', C=c)\n    scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')\n    acc_score.append(scores.mean())\nprint(acc_score) ","execution_count":17,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'cross_val_score' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-6103f392b8ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mC_range\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msvc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0macc_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'cross_val_score' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 위의 cross_val_score 관련 코드가 잘 실행되었다면,   \n# 아래 그래프 그리는 코드를 통해 1~26의 C 값 중\n# 어떤 값이 가장 좋은 정확도를 보이는지 확인할 수 있음.\n# C 값은 linear, RBF, polynomial kernel 모두 값을 변화시켜가며\n# 어떤 값이 가장 정확한 지 확인해볼 수 있음!\n\n\n#import matplotlib.pyplot as plt\n#%matplotlib inline\n#\n#C_values=list(range(1,26))\n#\n#plt.plot(C_values,acc_score)\n#plt.xticks(np.arange(0,27,2))\n#plt.xlabel('Value of C for SVC')\n#plt.ylabel('Cross-Validated Accuracy')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Gamma parameter는 RBF kernel의 inverse of the standard deviation 임.   \n즉, gamma parameter는 두 point 사이의 유사성을 의미함.   \nGamma 값을 작게 설정하면 큰 분산의 gaussian function이 가정됨.   \nGamma 값을 크게 설정하면 작은 분산의 gaussian function이 가정됨."},{"metadata":{"trusted":true},"cell_type":"code","source":"# 본 코드도 cross_val_score load의 오류로 인해 본 노트북에서는 실행하지 않음.\n\n\n#gamma_range=[0.0001,0.001,0.01,0.1,1,10,100]\n#acc_score=[]\n#for g in gamma_range:\n#    svc = SVC(kernel='rbf', gamma=g)\n#    scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')\n#    acc_score.append(scores.mean())\n#print(acc_score)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 위에서 계산한 gamma 값에 따른 정확도를 가시화 할 수 있는 코드\n\n#import matplotlib.pyplot as plt\n#%matplotlib inline\n#\n#gamma_range=[0.0001,0.001,0.01,0.1,1,10,100]\n#\n#plt.plot(gamma_range,acc_score)\n#plt.xlabel('Value of gamma for SVC ')\n#plt.xticks(np.arange(0.0001,100,5))\n#plt.ylabel('Cross-Validated Accuracy')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Degree 값에 따른 polynomial kernel"},{"metadata":{"trusted":true},"cell_type":"code","source":"#degree=[2,3,4,5,6]\n#acc_score=[]\n#for d in degree:\n#    svc = SVC(kernel='poly', degree=d)\n#    scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')\n#    acc_score.append(scores.mean())\n#print(acc_score) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import matplotlib.pyplot as plt\n#%matplotlib inline\n#\n#degree=[2,3,4,5,6]\n#\n#plt.plot(degree,acc_score,color='r')\n#plt.xlabel('degrees for SVC ')\n#plt.ylabel('Cross-Validated Accuracy')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"아래의 코드는 linear, RBF, polynomial kernel에서 C, gamma, degree 파라미터의 최적 값을 찾기 위한 코드.  \n본 코드는 sklearn.grid_search을 load해야 함.  \n본 노트북에서는 sklearn.grid_search가 load 되지 않아 수행해보진 못하였으나, 해당 모듈이 load 된다면 수행해보길 바랍니다!"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvm_model= SVC()","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tuned_parameters = {\n 'C': (np.arange(0.1,1,0.1)) , 'kernel': ['linear'],\n 'C': (np.arange(0.1,1,0.1)) , 'gamma': [0.01,0.02,0.03,0.04,0.05], 'kernel': ['rbf'],\n 'degree': [2,3,4] ,'gamma':[0.01,0.02,0.03,0.04,0.05], 'C':(np.arange(0.1,1,0.1)) , 'kernel':['poly']\n                   }","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.grid_search import GridSearchCV\nmodel_svm = GridSearchCV(svm_model, tuned_parameters,cv=10,scoring='accuracy')\n\nmodel_svm.fit(X_train, y_train)\nprint(model_svm.best_score_)\n\ny_pred= model_svm.predict(X_test)\nprint(metrics.accuracy_score(y_pred,y_test))","execution_count":21,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'sklearn.grid_search'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-3fb9b620f788>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_search\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_svm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuned_parameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.grid_search'"]}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}
